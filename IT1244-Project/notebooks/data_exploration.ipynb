{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_0.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_1.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_10.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_11.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_12.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_13.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_14.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_15.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_16.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_17.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_18.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_19.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_2.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_20.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_21.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_22.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_23.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_24.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_25.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_26.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_27.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_28.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_29.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_3.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_30.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_31.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_32.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_33.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_34.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_35.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_36.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_37.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_38.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_39.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_4.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_40.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_41.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_42.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_43.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_44.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_45.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_46.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_47.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_48.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_49.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_5.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_6.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_7.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_8.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/cat_9.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_0.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_1.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_10.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_11.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_12.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_13.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_14.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_15.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_16.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_17.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_18.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_19.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_2.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_20.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_21.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_22.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_23.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_24.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_25.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_26.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_27.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_28.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_29.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_3.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_30.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_31.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_32.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_33.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_34.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_35.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_36.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_37.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_38.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_39.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_4.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_40.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_41.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_42.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_43.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_44.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_45.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_46.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_5.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_6.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_7.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_8.wav', '../Dataset/Audio Dataset/Cats and Dogs/test_data/dog_9.wav']\n"
     ]
    }
   ],
   "source": [
    "# Show all wav files\n",
    "directory = '../Dataset/Audio Dataset/Cats and Dogs/test_data'\n",
    "files = sorted(glob.glob(os.path.join(directory, '*')))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the audio file\n",
    "# waveform, sample_rate = torchaudio.load(files[100])\n",
    "# print(waveform.shape)\n",
    "# print(sample_rate)\n",
    "\n",
    "# # Extract the spectrogram\n",
    "# spectrogram = torchaudio.transforms.Spectrogram(n_fft=2048, hop_length=512)(waveform)\n",
    "# mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=2048, hop_length=512, n_mels=128)(waveform)\n",
    "\n",
    "# # Check the shape\n",
    "# print(spectrogram.shape)\n",
    "# print(mel_spectrogram.shape)\n",
    "# print(mel_spectrogram)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110250, 110250, 39489, 110250, 110250, 110250, 110250, 110250, 351318, 110250, 229959, 110250, 110250, 356308, 110250, 110250, 110250, 110250, 30529, 110250, 110250, 110250, 110250, 110250, 510680, 110250, 110250, 329268, 110250, 110250, 110250, 110250, 110250, 110996, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 395983, 110250, 47105, 110250, 110250, 110250, 110250, 76661, 110250, 194746, 110250, 110250, 110250, 49409, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 66050, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 1483374, 90771, 110250, 134883, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250, 110250]\n",
      "137294.11340206186\n",
      "{22050: 97}\n"
     ]
    }
   ],
   "source": [
    "signal_lengths = []\n",
    "signal_sr={}\n",
    "for audio in files:\n",
    "    signal, sr = librosa.load(audio)\n",
    "    signal_lengths.append(len(signal))\n",
    "    if sr not in signal_sr:\n",
    "        signal_sr[sr]=0\n",
    "    signal_sr[sr] += 1\n",
    "\n",
    "print(signal_lengths)\n",
    "print(np.average(signal_lengths))\n",
    "print(signal_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascivenv",
   "language": "python",
   "name": "datascivenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
